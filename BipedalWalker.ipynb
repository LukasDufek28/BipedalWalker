{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Importy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "collapsed": true,
        "id": "3GNOkORKUhr9",
        "outputId": "e0b5840d-75a4-479c-d677-3859428348c6"
      },
      "outputs": [],
      "source": [
        "# Importy\n",
        "import gymnasium as gym\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import SAC,TD3 # Algoritmus\n",
        "from stable_baselines3.common.evaluation import evaluate_policy # Vyhodnotenie modelu\n",
        "from stable_baselines3.common.logger import configure # Logger pre tensorboard\n",
        "from stable_baselines3.common.noise import NormalActionNoise\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Check GPU\n",
        "print(\"GPU Available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "benchmark = \"BipedalWalkerHardcore-v3\"\n",
        "model_ = TD3  # A2C -> trenovat na CPU\n",
        "max_stepov_na_epizodu = 1000 # Target pre model\n",
        "num_envs = 6  # Number of parallel environments\n",
        "\n",
        "\n",
        "\n",
        "# Custom wrapper to penalize standing still\n",
        "class CustomBipedalWalker(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "\n",
        "# Create vectorized environments\n",
        "vec_env = SubprocVecEnv([lambda: CustomBipedalWalker(gym.make(benchmark, max_episode_steps=max_stepov_na_epizodu)) for _ in range(num_envs)])\n",
        "\n",
        "# Action noise\n",
        "action_noise = NormalActionNoise(\n",
        "    mean=np.zeros(vec_env.action_space.shape), \n",
        "    sigma=0.2 * np.ones(vec_env.action_space.shape)\n",
        ")\n",
        "\n",
        "# Definovanie modelu\n",
        "model = model_('MlpPolicy', vec_env, verbose=1, device=\"cuda\", action_noise=action_noise, tensorboard_log=\"./log/\" + model_.__name__ + \"_\" + benchmark, \n",
        "               batch_size=256, \n",
        "               learning_rate=0.001, \n",
        "               buffer_size=1000000, \n",
        "               gamma=0.99,\n",
        "               learning_starts=1000,\n",
        "               )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Trening**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model\n",
        "model.learn(total_timesteps=1000000, log_interval=1, progress_bar=True)\n",
        "\n",
        "# Evaluate policy\n",
        "mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=1, deterministic=False)\n",
        "print(f\"Priemerná odmena: {mean_reward} ± {std_reward}\")\n",
        "mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=1, deterministic=True)\n",
        "print(f\"Priemerná deterministic odmena: {mean_reward} ± {std_reward}\")\n",
        "\n",
        "# Save model\n",
        "model.save(model_.__name__ + \"_\" + benchmark + \"_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Testovanie**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MNEXNxnzWCyf",
        "outputId": "a9e4dd9c-0bf8-472b-ec07-7b400119bf14"
      },
      "outputs": [],
      "source": [
        "model = model_.load(model_.__name__ + \"_\" + benchmark + \"_model\") # Načítanie modelu\n",
        "env = gym.make(benchmark, render_mode=\"human\", max_episode_steps=max_stepov_na_epizodu)\n",
        "\n",
        "\n",
        "# Spustenie evaluacie\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10, deterministic=True)\n",
        "print(mean_reward, std_reward)\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
